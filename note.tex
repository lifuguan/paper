\documentclass[UTF8]{article} % chinese
% \usepackage{ctex}
%\documentclass{article}     %english
%\usepackage[nonatbib]{neurips}
\usepackage[final]{aneurips}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amsmath}
\usepackage{bm}
\usepackage{float}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{adjustbox}
\usepackage{color,xcolor,colortbl}
\usepackage[ruled, vlined, linesnumbered]{algorithm2e}
\newcommand{\mycomment}{\color{black}}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\graphicspath{{figure/}{images}}


\title{Paper Title}

\author{%
  Author First\thanks{corresponding author} \\
  Department of Computer \\
  Beijing University of Chemical Technology \\
  \texttt{first@mail.buct.edu.cn} \\
  \And
  Author Second \\  
  Department of Computer \\
  Beijing University of Chemical Technology \\
  \texttt{second@mail.buct.edu.cn} \\
}

\begin{document}

\maketitle

\begin{abstract}
Graph Neural Networks (GNN) is an emerging field for learning on non-Euclidean data. Recently, there has been great interest in designing GNN that scales to large graphs. Most existing techniques use ``graph sampling'' or ``layer-wise sampling'' technique to reduce training time. 

解决了什么问题？论文主要工作？效果如何？
~\\
~\\
~\\
\end{abstract}

\section{Experiments}
\subsection{Baseline and implementation}
We used a server equipped with an Intel Core i9-9980XE CPU @ 3.00GHz with 64GB RAM and 12GB of RTX2080Ti GPU for
our proposed networks training. The operating system of the sever is 64-bits Ubuntu 18.04. The structure of the network 
is implemented under the open source deep learning library Pytorch with VSCode implementation.

\subsection{Dataset}
For this study, we conduct our experiments on four differents segmentation tasks. 
Covering lesions/organs from most commonly used medical imaging modalities including microscopy, 
computed tomography (CT), and magnetic resonance imaging (MRI).  Table \ref{dataset-table} summarize those datasets in our study.

\begin{table}[ht]
  \vspace{-2mm}
  \begin{center}\small
  \caption{Summaey Of Biomedical Image Segmentation Datasets Used In Our Experiments}
  \label{dataset-table}
  \begin{tabular}{ccccc}
    
  \toprule
  Dataset & Image & Input Size & Modality & Provider\\
  \midrule
  Cell & 30 & $512\times 512$  & EM      & ISBI 2012\cite{isbicell}   \\
  Liver    & 4,000 & $512\times 512$       & CT     & MICCAI 2017 LiTS\cite{liver}  \\
  DSB2018      & 670 & $256\times 256$      & EM      & Kaggle\cite{dsb2018} \\
  COVID19         & 1,800 & $630\times 630$     & CT     & Web\cite{covid19,covid19_2}  \\
\bottomrule    
  \end{tabular}
  \end{center}
  %\vspace{-0.35cm}
  \vspace{-4mm}
  \end{table}

\paragraph{Cell}
The datset is the segmentation of neuronal structures in electron microscopic recordings.
The dataset is provided by the EM segmentation challenge\cite{isbicell} that is started at ISBI 2012.
The data is a set of 30 images ($512\times 512$ pixels) from serial section transmission electron
microscopy of the Drosophila first instar larva ventral nerve cord (VNC). Each image comes with a corresponding fully annotated ground truth segmentation
map for cells (white) and membranes (black).

\paragraph{Nuclei}
This dataset is a large number of segmented nuclei images\cite{dsb2018}
and is created for the Kaggle 2018 Data Science Bowl and consists of 670 segmented nuclei images
(\(256 \times 256\) pixels) from differenet modalities (brightfield vs. fluorescence). 
We resized them to \(512 \times 512\) for our experiments.

% \paragraph{Retinal Vessel} 
% The dataset is 2D Digital Retinal Images for Vessel Extraction (DRIVE) retina vessel\cite{drive}: DRIVE 
% contains 40 color pixels

\paragraph{Liver}
Liver tumor Segmentation Challenge (LiTS)\cite{liver} contain 131 contrast-enhanced CT images provided by hospital around the world with \(512 \times 512\) resolution.
The ground truth segmentation provides two different labels: liver and lesion. For our experiments,
we only consider liver as positive class and others as negative class.


\paragraph{COVID19}
Dataset\cite{covid19} includes whole volumes and includes, therefore, both positive and negative slices 
(373 out of the total of 829 slices have been evaluated by a radiologist as positive and segmented). 
Dataset\cite{covid19_2} contains 20 CT scans of patients diagnosed with COVID-19 as well as segmentations of lungs and infections made by experts.
These volumes are converted and normalized in a similar way as above, meanwhile we resize the data to $512\times 512$.

\paragraph{Lung}
Dataset\cite{covid19_2} also contains 20 CT scans of patients as well as segmentations of lungs made by experts with \(630 \times 630\) resolution.
We converted and normalized in a similar way as above, meanwhile we resize the data to $512\times 512$.

\subsection{Evaluation metrics}
The experiments are implemented using the Pytorch framework. We use Adam optimizer\cite{Adam} as our
models' optimizer with a learning rate of 0.00001, batch size of 2. All of datasets are splitted into training set and validation set with 
the ratio of 8:2 using sklearn library. To numerically evaluate, we use five widely adopted metrics, \(i.e.\),
the Dice similarity coefficient(Dice.), F1 score., Sensitivity(Sen.), Iou. and hausdorff distance(Hd)., the expressions of them are defined as follows:
\begin{align}
  \text { Sensitivity }=\frac{T P}{T P+F N}
\end{align}
\begin{align}
  \operatorname{DSC}(G, S)=\frac{2|G \cap S|}{|G|+|S|}
\end{align}
\begin{align}
  \operatorname{IOU}(G, S)=\frac{|G \cap S|}{|G| \cup|S|}
\end{align}
\begin{align}
  F_{1}=2 \cdot \frac{\text { precision } \cdot \text { recall }}{\text { precision }+\text { recall }}
\end{align}
\begin{align}
  h(G, S)=\max _{g \in G}\left\{\min _{c \in C}\|g-c\|\right\}
\end{align}
\subsection{Semantic Segmentation Results}
For comparsion, we use five origianl network FCN with 32s\cite{fcn}, U-Net\cite{unet}, U-Net++\cite{unet++} , CE-Net\cite{cenet} and U-Net with Attention Gate\cite{attentiongate}
to evaluate our proposaed method.


  \begin{table}[ht]
    \vspace{-2mm}
    \begin{center}\small
    \caption{Comparsion With Other Methods In Liver\cite{liver} Dataset}
    \label{dataset-table}
    \begin{tabular}{ccccccc}
      
    \toprule
    Dataset & Shape Loss & Dice. & F1 score. & Iou. & Sens. & Hd.\\
    \midrule
    Our proposal & $\surd$ & \textbf{0.9392} & \textbf{0.9392} & \textbf{0.8965} & \textbf{0.9261} & \textbf{3.8854}\\
    U-Net++ & $\times$ & 0.9351 & 0.9351 & 0.8781 & 0.9156 & 5.8218\\
     Attention UNet & $\times$ & 0.9346 & 0.9346 & 0.8776 & 0.9056 & 4.836\\
     CENet & $\times$ & 0.9315 & 0.9315 & 0.8721 & 0.9045 & 4.904\\
     U-Net & $\times$ & 0.9253 & 0.9253 & 0.8615 & 0.9106 & 6.6785\\
     FCN32s & $\times$ & 0.9065 & 0.9065 & 0.8300 & 0.9381 & 7.97\\
  \bottomrule    
    \end{tabular}
    \end{center}
    \vspace{-4mm}
  \end{table}

    
  \begin{table}[ht]
    \vspace{-2mm}
    \begin{center}\small
    \caption{Comparsion With Other Methods In Lung\cite{covid19_2} Dataset}
    \label{dataset-table}
    \begin{tabular}{ccccccc}
      
    \toprule
    Dataset & Shape Loss & Dice. & F1 score. & Iou. & Sens. & Hd.\\
    \midrule
      Our proposal & $\surd$ & \textbf{0.9392} & \textbf{0.9392} & \textbf{0.8965} & \textbf{0.9261} & \textbf{10.19714}\\
      UNet++ & $\times$ & 0.9351 & 0.9351 & 0.8781 & 0.9156 & 5.8218\\
      Attention UNet & $\times$ & 0.9346 & 0.9346 & 0.8776 & 0.9056 & 4.836\\
      CENet & $\times$ & 0.9315 & 0.9315 & 0.8721 & 0.9045 & 4.904\\
      UNet & $\times$ & 0.9253 & 0.9253 & 0.8615 & 0.9106 & 6.6785\\
      FCN32s & $\times$ & 0.9065 & 0.9065 & 0.8300 & 0.9381 & 7.97\\
  \bottomrule    
    \end{tabular}
    \end{center}
    %\vspace{-0.35cm}
    \vspace{-4mm}
  \end{table}


\section{Conclusion}
~\\
~\\
~\\

\section*{Acknowledgments}
~\\
~\\
~\\

\bibliographystyle{abbrv}
\bibliography{complete.bib}
\end{document}
